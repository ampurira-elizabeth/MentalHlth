{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fb90d0",
   "metadata": {},
   "source": [
    "# Mental Health Time Series Analysis\n",
    "\n",
    "This notebook performs comprehensive time series analysis including:\n",
    "- Trend analysis and decomposition\n",
    "- Seasonality detection\n",
    "- Forecasting future trends\n",
    "- Cross-country comparative analysis\n",
    "- Statistical significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790b3f1",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d551df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series specific imports\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "# Import custom modules\n",
    "from analysis.time_series import TimeSeriesAnalyzer\n",
    "from analysis.statistical_tests import StatisticalTests\n",
    "from visualization.static_plots import StaticPlots\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec347b2",
   "metadata": {},
   "source": [
    "## 2. Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "data_path = Path(\"../data/processed/mental_health_cleaned.csv\")\n",
    "\n",
    "if data_path.exists():\n",
    "    data = pd.read_csv(data_path)\n",
    "    print(f\"✓ Cleaned data loaded: {data.shape}\")\n",
    "else:\n",
    "    print(\"❌ Cleaned data not found. Please run data cleaning notebook first.\")\n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    years = list(range(1990, 2024))\n",
    "    countries = ['United States', 'United Kingdom', 'Germany', 'France', 'Japan']\n",
    "    \n",
    "    sample_data = []\n",
    "    for country in countries:\n",
    "        base_rate = np.random.uniform(4, 8)\n",
    "        for year in years:\n",
    "            trend = (year - 1990) * 0.03\n",
    "            noise = np.random.normal(0, 0.5)\n",
    "            sample_data.append({\n",
    "                'Entity': country,\n",
    "                'Year': year,\n",
    "                'Depression_prevalence': max(0, base_rate + trend + noise),\n",
    "                'Anxiety_prevalence': max(0, base_rate * 0.8 + trend + noise)\n",
    "            })\n",
    "    \n",
    "    data = pd.DataFrame(sample_data)\n",
    "    print(f\"⚠️ Using sample data: {data.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\nDataset overview:\")\n",
    "print(f\"  Countries: {data['Entity'].nunique()}\")\n",
    "print(f\"  Years: {data['Year'].min()} - {data['Year'].max()}\")\n",
    "print(f\"  Records: {len(data):,}\")\n",
    "\n",
    "# Identify prevalence columns\n",
    "prevalence_cols = [col for col in data.columns if 'prevalence' in col.lower()]\n",
    "print(f\"  Mental health metrics: {len(prevalence_cols)}\")\n",
    "for col in prevalence_cols:\n",
    "    print(f\"    • {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606e852",
   "metadata": {},
   "source": [
    "## 3. Initialize Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5769387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analysis modules\n",
    "ts_analyzer = TimeSeriesAnalyzer()\n",
    "stat_tests = StatisticalTests()\n",
    "plotter = StaticPlots()\n",
    "\n",
    "print(\"✓ Analysis tools initialized\")\n",
    "\n",
    "# Set analysis parameters\n",
    "country_col = 'Entity'\n",
    "year_col = 'Year'\n",
    "main_metric = prevalence_cols[0] if prevalence_cols else None\n",
    "\n",
    "print(f\"Primary analysis metric: {main_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47874056",
   "metadata": {},
   "source": [
    "## 4. Global Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd399c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_metric:\n",
    "    print(\"=== GLOBAL TREND ANALYSIS ===\")\n",
    "    \n",
    "    # Calculate global average by year\n",
    "    global_trends = data.groupby(year_col)[main_metric].agg(['mean', 'std', 'count']).reset_index()\n",
    "    global_trends.columns = [year_col, 'Mean_Prevalence', 'Std_Prevalence', 'Country_Count']\n",
    "    \n",
    "    print(f\"Global trend data shape: {global_trends.shape}\")\n",
    "    print(f\"Year range: {global_trends[year_col].min()} - {global_trends[year_col].max()}\")\n",
    "    \n",
    "    # Analyze global trend\n",
    "    trend_analysis = ts_analyzer.analyze_trend(global_trends[year_col], global_trends['Mean_Prevalence'])\n",
    "    \n",
    "    print(f\"\\nGlobal trend analysis:\")\n",
    "    print(f\"  Slope: {trend_analysis['slope']:.4f} per year\")\n",
    "    print(f\"  P-value: {trend_analysis['p_value']:.6f}\")\n",
    "    print(f\"  R-squared: {trend_analysis['r_squared']:.4f}\")\n",
    "    print(f\"  Trend direction: {trend_analysis['trend_direction']}\")\n",
    "    print(f\"  Significance: {'Significant' if trend_analysis['is_significant'] else 'Not significant'}\")\n",
    "    \n",
    "    # Visualize global trend\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Main trend plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(global_trends[year_col], global_trends['Mean_Prevalence'], 'o-', linewidth=2, markersize=6)\n",
    "    plt.fill_between(global_trends[year_col], \n",
    "                     global_trends['Mean_Prevalence'] - global_trends['Std_Prevalence'],\n",
    "                     global_trends['Mean_Prevalence'] + global_trends['Std_Prevalence'],\n",
    "                     alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(global_trends[year_col], global_trends['Mean_Prevalence'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(global_trends[year_col], p(global_trends[year_col]), '--r', linewidth=2, label=f'Trend (slope={z[0]:.4f})')\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(f'Average {main_metric.replace(\"_\", \" \").title()} (%)')\n",
    "    plt.title('Global Mental Health Trend')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Year-over-year change\n",
    "    plt.subplot(2, 2, 2)\n",
    "    yoy_change = global_trends['Mean_Prevalence'].pct_change() * 100\n",
    "    plt.bar(global_trends[year_col][1:], yoy_change[1:], alpha=0.7)\n",
    "    plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Year-over-Year Change (%)')\n",
    "    plt.title('Annual Change in Global Prevalence')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution over time\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(global_trends['Mean_Prevalence'], bins=15, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel(f'{main_metric.replace(\"_\", \" \").title()} (%)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Annual Global Averages')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Data availability\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(global_trends[year_col], global_trends['Country_Count'], 'g-o', linewidth=2)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Countries')\n",
    "    plt.title('Data Availability Over Time')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d13cc",
   "metadata": {},
   "source": [
    "## 5. Country-Specific Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_metric:\n",
    "    print(\"=== COUNTRY-SPECIFIC TRENDS ===\")\n",
    "    \n",
    "    # Get top countries by data availability\n",
    "    country_data_counts = data.groupby(country_col).size().sort_values(ascending=False)\n",
    "    top_countries = country_data_counts.head(10).index.tolist()\n",
    "    \n",
    "    print(f\"Analyzing trends for top {len(top_countries)} countries with most data\")\n",
    "    \n",
    "    # Analyze trends for each country\n",
    "    country_trends = {}\n",
    "    trend_summary = []\n",
    "    \n",
    "    for country in top_countries:\n",
    "        country_data = data[data[country_col] == country].copy()\n",
    "        country_data = country_data.sort_values(year_col)\n",
    "        \n",
    "        if len(country_data) >= 10:  # Need sufficient data points\n",
    "            trend_analysis = ts_analyzer.analyze_trend(\n",
    "                country_data[year_col], \n",
    "                country_data[main_metric]\n",
    "            )\n",
    "            \n",
    "            country_trends[country] = {\n",
    "                'data': country_data,\n",
    "                'trend': trend_analysis\n",
    "            }\n",
    "            \n",
    "            trend_summary.append({\n",
    "                'Country': country,\n",
    "                'Slope': trend_analysis['slope'],\n",
    "                'P_Value': trend_analysis['p_value'],\n",
    "                'R_Squared': trend_analysis['r_squared'],\n",
    "                'Trend_Direction': trend_analysis['trend_direction'],\n",
    "                'Is_Significant': trend_analysis['is_significant'],\n",
    "                'Data_Points': len(country_data)\n",
    "            })\n",
    "    \n",
    "    # Create trend summary dataframe\n",
    "    trend_df = pd.DataFrame(trend_summary)\n",
    "    trend_df = trend_df.sort_values('Slope', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTrend analysis completed for {len(trend_df)} countries\")\n",
    "    print(f\"Significant increasing trends: {len(trend_df[(trend_df['Is_Significant']) & (trend_df['Slope'] > 0)])}\")\n",
    "    print(f\"Significant decreasing trends: {len(trend_df[(trend_df['Is_Significant']) & (trend_df['Slope'] < 0)])}\")\n",
    "    \n",
    "    # Display trend summary\n",
    "    print(\"\\nTop 10 Countries by Trend Slope:\")\n",
    "    display(trend_df.head(10)[['Country', 'Slope', 'Trend_Direction', 'Is_Significant', 'R_Squared']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf28a3",
   "metadata": {},
   "source": [
    "## 6. Visualize Country Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if country_trends and main_metric:\n",
    "    print(\"=== COUNTRY TREND VISUALIZATION ===\")\n",
    "    \n",
    "    # Plot trends for top countries\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    countries_to_plot = list(country_trends.keys())[:6]\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(countries_to_plot)))\n",
    "    \n",
    "    for i, country in enumerate(countries_to_plot):\n",
    "        country_info = country_trends[country]\n",
    "        country_data = country_info['data']\n",
    "        trend_info = country_info['trend']\n",
    "        \n",
    "        # Plot data points\n",
    "        axes[i].scatter(country_data[year_col], country_data[main_metric], \n",
    "                       alpha=0.7, s=50, color=colors[i])\n",
    "        \n",
    "        # Plot trend line\n",
    "        z = np.polyfit(country_data[year_col], country_data[main_metric], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[i].plot(country_data[year_col], p(country_data[year_col]), \n",
    "                    '--', linewidth=2, color='red')\n",
    "        \n",
    "        # Formatting\n",
    "        significance = '***' if trend_info['p_value'] < 0.001 else '**' if trend_info['p_value'] < 0.01 else '*' if trend_info['p_value'] < 0.05 else ''\n",
    "        title = f\"{country}\\nSlope: {trend_info['slope']:.4f}{significance}\\nR²: {trend_info['r_squared']:.3f}\"\n",
    "        \n",
    "        axes[i].set_title(title, fontsize=10)\n",
    "        axes[i].set_xlabel('Year')\n",
    "        axes[i].set_ylabel(f'{main_metric.replace(\"_\", \" \").title()} (%)')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Mental Health Trends by Country ({main_metric.replace(\"_\", \" \").title()})', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Comparative trend plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    for i, country in enumerate(countries_to_plot):\n",
    "        country_data = country_trends[country]['data']\n",
    "        plt.plot(country_data[year_col], country_data[main_metric], \n",
    "                'o-', label=country, linewidth=2, markersize=4)\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(f'{main_metric.replace(\"_\", \" \").title()} (%)')\n",
    "    plt.title('Comparative Mental Health Trends')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8ad5b",
   "metadata": {},
   "source": [
    "## 7. Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_metric and len(global_trends) >= 8:\n",
    "    print(\"=== TIME SERIES DECOMPOSITION ===\")\n",
    "    \n",
    "    # Perform decomposition on global trend\n",
    "    try:\n",
    "        # Prepare time series\n",
    "        ts_data = global_trends.set_index(year_col)['Mean_Prevalence']\n",
    "        \n",
    "        # Decomposition\n",
    "        decomposition = seasonal_decompose(ts_data, model='additive', period=min(4, len(ts_data)//2))\n",
    "        \n",
    "        # Plot decomposition\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "        \n",
    "        # Original\n",
    "        decomposition.observed.plot(ax=axes[0], title='Original Time Series')\n",
    "        axes[0].set_ylabel('Prevalence (%)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Trend\n",
    "        decomposition.trend.plot(ax=axes[1], title='Trend Component', color='orange')\n",
    "        axes[1].set_ylabel('Trend')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Seasonal\n",
    "        decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component', color='green')\n",
    "        axes[2].set_ylabel('Seasonal')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Residual\n",
    "        decomposition.resid.plot(ax=axes[3], title='Residual Component', color='red')\n",
    "        axes[3].set_ylabel('Residual')\n",
    "        axes[3].set_xlabel('Year')\n",
    "        axes[3].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Time Series Decomposition - Global Mental Health Trend', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyze components\n",
    "        trend_strength = 1 - (decomposition.resid.var() / decomposition.observed.var())\n",
    "        seasonal_strength = 1 - (decomposition.resid.var() / (decomposition.observed - decomposition.trend).var())\n",
    "        \n",
    "        print(f\"\\nDecomposition Analysis:\")\n",
    "        print(f\"  Trend strength: {trend_strength:.3f}\")\n",
    "        print(f\"  Seasonal strength: {seasonal_strength:.3f}\")\n",
    "        print(f\"  Residual variance: {decomposition.resid.var():.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not perform decomposition: {e}\")\n",
    "        print(\"This might be due to insufficient data points or irregular time series\")\n",
    "else:\n",
    "    print(\"Insufficient data for time series decomposition (need at least 8 data points)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aba2c91",
   "metadata": {},
   "source": [
    "## 8. Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_metric and len(global_trends) >= 5:\n",
    "    print(\"=== MENTAL HEALTH TREND FORECASTING ===\")\n",
    "    \n",
    "    # Prepare data for forecasting\n",
    "    ts_data = global_trends.set_index(year_col)['Mean_Prevalence']\n",
    "    forecast_horizon = 5  # 5 years into the future\n",
    "    \n",
    "    print(f\"Training data: {len(ts_data)} years ({ts_data.index.min()} - {ts_data.index.max()})\")\n",
    "    print(f\"Forecast horizon: {forecast_horizon} years\")\n",
    "    \n",
    "    # Method 1: Linear trend extrapolation\n",
    "    print(\"\\n1. Linear Trend Extrapolation\")\n",
    "    future_years = list(range(ts_data.index.max() + 1, ts_data.index.max() + forecast_horizon + 1))\n",
    "    \n",
    "    # Fit linear trend\n",
    "    z = np.polyfit(ts_data.index, ts_data.values, 1)\n",
    "    linear_forecast = np.poly1d(z)(future_years)\n",
    "    \n",
    "    # Method 2: Exponential Smoothing (if possible)\n",
    "    exp_forecast = None\n",
    "    try:\n",
    "        print(\"\\n2. Exponential Smoothing\")\n",
    "        exp_model = ExponentialSmoothing(ts_data, trend='add', seasonal=None)\n",
    "        exp_fit = exp_model.fit()\n",
    "        exp_forecast = exp_fit.forecast(forecast_horizon)\n",
    "        print(f\"  Exponential smoothing successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Exponential smoothing failed: {e}\")\n",
    "    \n",
    "    # Method 3: ARIMA (if possible)\n",
    "    arima_forecast = None\n",
    "    try:\n",
    "        print(\"\\n3. ARIMA Model\")\n",
    "        arima_model = ARIMA(ts_data, order=(1, 1, 1))\n",
    "        arima_fit = arima_model.fit()\n",
    "        arima_forecast = arima_fit.forecast(forecast_horizon)\n",
    "        print(f\"  ARIMA model successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ARIMA model failed: {e}\")\n",
    "    \n",
    "    # Visualize forecasts\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Historical data\n",
    "    plt.plot(ts_data.index, ts_data.values, 'o-', linewidth=2, markersize=6, label='Historical Data')\n",
    "    \n",
    "    # Linear forecast\n",
    "    plt.plot(future_years, linear_forecast, 's--', linewidth=2, label='Linear Trend Forecast', alpha=0.8)\n",
    "    \n",
    "    # Exponential smoothing forecast\n",
    "    if exp_forecast is not None:\n",
    "        plt.plot(future_years, exp_forecast, '^--', linewidth=2, label='Exponential Smoothing', alpha=0.8)\n",
    "    \n",
    "    # ARIMA forecast\n",
    "    if arima_forecast is not None:\n",
    "        plt.plot(future_years, arima_forecast, 'd--', linewidth=2, label='ARIMA Forecast', alpha=0.8)\n",
    "    \n",
    "    # Add vertical line to separate historical from forecast\n",
    "    plt.axvline(x=ts_data.index.max(), color='red', linestyle=':', alpha=0.7, label='Forecast Start')\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel(f'{main_metric.replace(\"_\", \" \").title()} (%)')\n",
    "    plt.title('Mental Health Trend Forecasting')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display forecast values\n",
    "    print(f\"\\n=== FORECAST RESULTS ===\")\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'Year': future_years,\n",
    "        'Linear_Trend': linear_forecast\n",
    "    })\n",
    "    \n",
    "    if exp_forecast is not None:\n",
    "        forecast_df['Exponential_Smoothing'] = exp_forecast.values\n",
    "    \n",
    "    if arima_forecast is not None:\n",
    "        forecast_df['ARIMA'] = arima_forecast.values\n",
    "    \n",
    "    display(forecast_df)\n",
    "    \n",
    "    # Calculate forecast statistics\n",
    "    print(f\"\\nForecast Summary:\")\n",
    "    print(f\"  Linear trend change over {forecast_horizon} years: {linear_forecast[-1] - linear_forecast[0]:.3f}%\")\n",
    "    if exp_forecast is not None:\n",
    "        print(f\"  Exponential smoothing change: {exp_forecast.iloc[-1] - exp_forecast.iloc[0]:.3f}%\")\n",
    "    if arima_forecast is not None:\n",
    "        print(f\"  ARIMA change: {arima_forecast.iloc[-1] - arima_forecast.iloc[0]:.3f}%\")\n",
    "        \n",
    "else:\n",
    "    print(\"Insufficient data for forecasting (need at least 5 data points)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d1d9c",
   "metadata": {},
   "source": [
    "## 9. Statistical Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_metric and len(trend_df) >= 2:\n",
    "    print(\"=== STATISTICAL SIGNIFICANCE TESTING ===\")\n",
    "    \n",
    "    # Test 1: Are trends significantly different from zero?\n",
    "    print(\"\\n1. Testing if country trends are significantly different from zero:\")\n",
    "    slopes = trend_df['Slope'].values\n",
    "    t_stat, p_value = stats.ttest_1samp(slopes, 0)\n",
    "    \n",
    "    print(f\"  Mean slope: {slopes.mean():.6f}\")\n",
    "    print(f\"  Standard deviation: {slopes.std():.6f}\")\n",
    "    print(f\"  T-statistic: {t_stat:.4f}\")\n",
    "    print(f\"  P-value: {p_value:.6f}\")\n",
    "    print(f\"  Conclusion: {'Trends are significantly different from zero' if p_value < 0.05 else 'No significant trend'}\")\n",
    "    \n",
    "    # Test 2: Compare trends between regions (if region data available)\n",
    "    if 'Region' in data.columns:\n",
    "        print(\"\\n2. Regional comparison of trends:\")\n",
    "        \n",
    "        # Calculate regional trends\n",
    "        regional_trends = []\n",
    "        for region in data['Region'].unique():\n",
    "            region_data = data[data['Region'] == region]\n",
    "            if len(region_data) >= 10:\n",
    "                region_trend = region_data.groupby(year_col)[main_metric].mean()\n",
    "                if len(region_trend) >= 5:\n",
    "                    slope, _, _, p_val, _ = stats.linregress(region_trend.index, region_trend.values)\n",
    "                    regional_trends.append({\n",
    "                        'Region': region,\n",
    "                        'Slope': slope,\n",
    "                        'P_Value': p_val,\n",
    "                        'Countries': region_data['Entity'].nunique()\n",
    "                        'Data_Points': len(region_data)\n",
    "                    })\n",
    "        \n",
    "        if regional_trends:\n",
    "            regional_df = pd.DataFrame(regional_trends)\n",
    "            print(\"  Regional trend analysis:\")\n",
    "            display(regional_df)\n",
    "            \n",
    "            # Test if regional trends are significantly different\n",
    "            if len(regional_df) >= 2:\n",
    "                f_stat, f_p_value = stats.f_oneway(*[regional_df[regional_df['Region'] == region]['Slope'].values for region in regional_df['Region']])\n",
    "                print(f\"\\n  ANOVA F-test for regional differences:\")\n",
    "                print(f\"    F-statistic: {f_stat:.4f}\")\n",
    "                print(f\"    P-value: {f_p_value:.6f}\")\n",
    "                print(f\"    Conclusion: {'Significant regional differences' if f_p_value < 0.05 else 'No significant regional differences'}\")\n",
    "    \n",
    "    # Test 3: Correlation between prevalence metrics\n",
    "    if len(prevalence_cols) >= 2:\n",
    "        print(\"\\n3. Correlation between mental health metrics:\")\n",
    "        \n",
    "        correlation_matrix = data[prevalence_cols].corr()\n",
    "        print(\"  Correlation matrix:\")\n",
    "        display(correlation_matrix)\n",
    "        \n",
    "        # Visualize correlation matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, fmt='.3f', cbar_kws={'label': 'Correlation Coefficient'})\n",
    "        plt.title('Correlation Between Mental Health Metrics')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Test significance of correlations\n",
    "        print(\"\\n  Correlation significance tests:\")\n",
    "        for i, col1 in enumerate(prevalence_cols):\n",
    "            for col2 in prevalence_cols[i+1:]:\n",
    "                clean_data = data[[col1, col2]].dropna()\n",
    "                if len(clean_data) >= 10:\n",
    "                    corr_coef, corr_p_value = stats.pearsonr(clean_data[col1], clean_data[col2])\n",
    "                    significance = '***' if corr_p_value < 0.001 else '**' if corr_p_value < 0.01 else '*' if corr_p_value < 0.05 else ''\n",
    "                    print(f\"    {col1} vs {col2}: r = {corr_coef:.3f}{significance} (p = {corr_p_value:.6f})\")\n",
    "else:\n",
    "    print(\"Insufficient data for statistical testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e32f7a",
   "metadata": {},
   "source": [
    "## 10. Save Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save time series analysis results\n",
    "results_path = Path(\"../data/processed\")\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Compile analysis results\n",
    "analysis_results = {\n",
    "    'global_trend': {\n",
    "        'data_shape': global_trends.shape if 'global_trends' in locals() else (0, 0),\n",
    "        'trend_analysis': trend_analysis if 'trend_analysis' in locals() else {},\n",
    "        'year_range': [global_trends[year_col].min(), global_trends[year_col].max()] if 'global_trends' in locals() else []\n",
    "    },\n",
    "    'country_trends': {\n",
    "        'countries_analyzed': len(trend_df) if 'trend_df' in locals() else 0,\n",
    "        'significant_increasing': len(trend_df[(trend_df['Is_Significant']) & (trend_df['Slope'] > 0)]) if 'trend_df' in locals() else 0,\n",
    "        'significant_decreasing': len(trend_df[(trend_df['Is_Significant']) & (trend_df['Slope'] < 0)]) if 'trend_df' in locals() else 0\n",
    "    },\n",
    "    'forecasting': {\n",
    "        'methods_used': ['Linear Trend'],\n",
    "        'forecast_horizon': forecast_horizon if 'forecast_horizon' in locals() else 0,\n",
    "        'linear_forecast': linear_forecast.tolist() if 'linear_forecast' in locals() else []\n",
    "    },\n",
    "    'statistical_tests': {\n",
    "        'trend_significance_test': {\n",
    "            'mean_slope': slopes.mean() if 'slopes' in locals() else 0,\n",
    "            'p_value': p_value if 'p_value' in locals() else 1,\n",
    "            'significant': p_value < 0.05 if 'p_value' in locals() else False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "import json\n",
    "results_file = results_path / \"time_series_analysis_results.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "print(f\"✅ Time series analysis results saved to: {results_file}\")\n",
    "\n",
    "# Save country trends if available\n",
    "if 'trend_df' in locals():\n",
    "    trend_file = results_path / \"country_trends.csv\"\n",
    "    trend_df.to_csv(trend_file, index=False)\n",
    "    print(f\"✅ Country trends saved to: {trend_file}\")\n",
    "\n",
    "# Save forecast data if available\n",
    "if 'forecast_df' in locals():\n",
    "    forecast_file = results_path / \"forecast_results.csv\"\n",
    "    forecast_df.to_csv(forecast_file, index=False)\n",
    "    print(f\"✅ Forecast results saved to: {forecast_file}\")\n",
    "\n",
    "print(f\"\\n🎉 Time series analysis completed successfully!\")\n",
    "print(f\"📊 Key findings:\")\n",
    "if 'trend_analysis' in locals():\n",
    "    print(f\"  • Global trend: {trend_analysis['trend_direction']} ({'significant' if trend_analysis['is_significant'] else 'not significant'})\")\n",
    "if 'trend_df' in locals():\n",
    "    print(f\"  • Countries analyzed: {len(trend_df)}\")\n",
    "    print(f\"  • Countries with significant trends: {len(trend_df[trend_df['Is_Significant']])}\")\n",
    "if 'forecast_horizon' in locals():\n",
    "    print(f\"  • Forecast horizon: {forecast_horizon} years\")\n",
    "\n",
    "print(f\"\\n📁 Proceed to notebook 04_visualization.ipynb for advanced visualizations\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
