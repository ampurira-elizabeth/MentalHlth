{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47de846d",
   "metadata": {},
   "source": [
    "# Mental Health Data Exploration\n",
    "\n",
    "This notebook provides an initial exploration of the global mental health dataset, including:\n",
    "- Data loading and overview\n",
    "- Basic statistics and data quality assessment\n",
    "- Initial visualizations\n",
    "- Data structure analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d4a78",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ea33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb97db",
   "metadata": {},
   "source": [
    "## 2. Load and Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data acquisition module\n",
    "from data.download_data import DataDownloader\n",
    "\n",
    "# Initialize data downloader\n",
    "downloader = DataDownloader(data_dir=\"../data\")\n",
    "\n",
    "# Download all datasets\n",
    "print(\"Downloading mental health datasets...\")\n",
    "success = downloader.download_all_data()\n",
    "\n",
    "if success:\n",
    "    print(\"‚úì Data download completed successfully!\")\n",
    "    \n",
    "    # Get information about downloaded files\n",
    "    info = downloader.get_data_info()\n",
    "    print(\"\\nDownloaded files:\")\n",
    "    for category, files in info.items():\n",
    "        print(f\"  {category}: {len(files)} files\")\n",
    "        for file in files:\n",
    "            print(f\"    - {file.name}\")\n",
    "else:\n",
    "    print(\"‚ùå Data download failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f2939e",
   "metadata": {},
   "source": [
    "## 3. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw mental health data\n",
    "data_path = Path(\"../data/raw/mental_health_prevalence.csv\")\n",
    "\n",
    "if data_path.exists():\n",
    "    raw_data = pd.read_csv(data_path)\n",
    "    print(f\"‚úì Data loaded successfully: {raw_data.shape}\")\n",
    "    print(f\"  Rows: {raw_data.shape[0]:,}\")\n",
    "    print(f\"  Columns: {raw_data.shape[1]}\")\n",
    "else:\n",
    "    print(\"‚ùå Data file not found. Please run the data download cell first.\")\n",
    "    raw_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0078df",
   "metadata": {},
   "source": [
    "## 4. Initial Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    print(\"=== DATA OVERVIEW ===\")\n",
    "    print(f\"Dataset shape: {raw_data.shape}\")\n",
    "    print(f\"Memory usage: {raw_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(\"\\n=== COLUMN INFORMATION ===\")\n",
    "    print(raw_data.info())\n",
    "    \n",
    "    print(\"\\n=== COLUMN NAMES ===\")\n",
    "    for i, col in enumerate(raw_data.columns):\n",
    "        print(f\"{i+1:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    print(\"=== FIRST 10 ROWS ===\")\n",
    "    display(raw_data.head(10))\n",
    "    \n",
    "    print(\"\\n=== LAST 5 ROWS ===\")\n",
    "    display(raw_data.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f402336",
   "metadata": {},
   "source": [
    "## 5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e78172",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    print(\"=== MISSING VALUES ANALYSIS ===\")\n",
    "    missing_info = raw_data.isnull().sum()\n",
    "    missing_pct = (missing_info / len(raw_data)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing_info,\n",
    "        'Missing Percentage': missing_pct\n",
    "    }).sort_values('Missing Count', ascending=False)\n",
    "    \n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    # Visualize missing data\n",
    "    if missing_df['Missing Count'].sum() > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        missing_cols = missing_df[missing_df['Missing Count'] > 0]\n",
    "        plt.bar(range(len(missing_cols)), missing_cols['Missing Percentage'])\n",
    "        plt.xlabel('Columns')\n",
    "        plt.ylabel('Missing Percentage (%)')\n",
    "        plt.title('Missing Data by Column')\n",
    "        plt.xticks(range(len(missing_cols)), missing_cols.index, rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚úì No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1975113",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    print(\"=== BASIC STATISTICS ===\")\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_cols = raw_data.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        display(raw_data[numeric_cols].describe())\n",
    "    \n",
    "    print(\"\\n=== CATEGORICAL COLUMNS ===\")\n",
    "    categorical_cols = raw_data.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        unique_count = raw_data[col].nunique()\n",
    "        print(f\"{col}: {unique_count} unique values\")\n",
    "        if unique_count <= 20:  # Show values if not too many\n",
    "            print(f\"  Values: {sorted(raw_data[col].unique().tolist())}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9488d",
   "metadata": {},
   "source": [
    "## 6. Geographic and Temporal Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747681fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    # Identify country and year columns\n",
    "    country_col = None\n",
    "    year_col = None\n",
    "    \n",
    "    for col in raw_data.columns:\n",
    "        if 'entity' in col.lower() or 'country' in col.lower():\n",
    "            country_col = col\n",
    "        elif 'year' in col.lower():\n",
    "            year_col = col\n",
    "    \n",
    "    if country_col and year_col:\n",
    "        print(f\"=== GEOGRAPHIC COVERAGE (using {country_col}) ===\")\n",
    "        print(f\"Total unique countries/entities: {raw_data[country_col].nunique()}\")\n",
    "        \n",
    "        # Show top countries by data points\n",
    "        country_counts = raw_data[country_col].value_counts().head(15)\n",
    "        print(\"\\nTop 15 countries by data points:\")\n",
    "        for country, count in country_counts.items():\n",
    "            print(f\"  {country}: {count} records\")\n",
    "        \n",
    "        print(f\"\\n=== TEMPORAL COVERAGE (using {year_col}) ===\")\n",
    "        year_range = raw_data[year_col].agg(['min', 'max'])\n",
    "        print(f\"Year range: {year_range['min']} - {year_range['max']}\")\n",
    "        print(f\"Total years covered: {raw_data[year_col].nunique()}\")\n",
    "        \n",
    "        # Visualize temporal coverage\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        # Data points per year\n",
    "        plt.subplot(1, 2, 1)\n",
    "        year_counts = raw_data[year_col].value_counts().sort_index()\n",
    "        plt.plot(year_counts.index, year_counts.values, marker='o')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Number of Records')\n",
    "        plt.title('Data Points per Year')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Countries per year\n",
    "        plt.subplot(1, 2, 2)\n",
    "        countries_per_year = raw_data.groupby(year_col)[country_col].nunique()\n",
    "        plt.plot(countries_per_year.index, countries_per_year.values, marker='s', color='green')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Number of Countries')\n",
    "        plt.title('Countries with Data per Year')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Could not identify country and year columns for coverage analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620c28a",
   "metadata": {},
   "source": [
    "## 7. Mental Health Metrics Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82876372",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    # Identify prevalence columns\n",
    "    prevalence_cols = [col for col in raw_data.columns if 'prevalence' in col.lower()]\n",
    "    \n",
    "    print(f\"=== MENTAL HEALTH METRICS ({len(prevalence_cols)} found) ===\")\n",
    "    for i, col in enumerate(prevalence_cols, 1):\n",
    "        print(f\"{i}. {col}\")\n",
    "    \n",
    "    if prevalence_cols:\n",
    "        print(\"\\n=== PREVALENCE STATISTICS ===\")\n",
    "        display(raw_data[prevalence_cols].describe())\n",
    "        \n",
    "        # Visualize distributions\n",
    "        n_metrics = len(prevalence_cols)\n",
    "        if n_metrics > 0:\n",
    "            fig, axes = plt.subplots(2, min(2, n_metrics), figsize=(15, 10))\n",
    "            if n_metrics == 1:\n",
    "                axes = np.array([axes]).flatten()\n",
    "            elif n_metrics == 2:\n",
    "                axes = axes.flatten()\n",
    "            \n",
    "            for i, col in enumerate(prevalence_cols[:4]):  # Show up to 4 metrics\n",
    "                if i < len(axes):\n",
    "                    data_to_plot = raw_data[col].dropna()\n",
    "                    if len(data_to_plot) > 0:\n",
    "                        axes[i].hist(data_to_plot, bins=30, alpha=0.7, edgecolor='black')\n",
    "                        axes[i].set_title(col.replace('_', ' ').title())\n",
    "                        axes[i].set_xlabel('Prevalence (%)')\n",
    "                        axes[i].set_ylabel('Frequency')\n",
    "                        axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Hide unused subplots\n",
    "            for i in range(len(prevalence_cols), len(axes)):\n",
    "                axes[i].set_visible(False)\n",
    "            \n",
    "            plt.suptitle('Distribution of Mental Health Prevalence Metrics', fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No prevalence columns found in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f792c",
   "metadata": {},
   "source": [
    "## 8. Sample Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None and country_col and year_col:\n",
    "    print(\"=== SAMPLE COUNTRY ANALYSIS ===\")\n",
    "    \n",
    "    # Get a sample country with good data coverage\n",
    "    country_data_counts = raw_data[country_col].value_counts()\n",
    "    sample_countries = country_data_counts.head(5).index.tolist()\n",
    "    \n",
    "    print(f\"Analyzing sample countries: {sample_countries}\")\n",
    "    \n",
    "    if prevalence_cols:\n",
    "        # Create time series for sample countries\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, len(sample_countries)))\n",
    "        \n",
    "        for i, country in enumerate(sample_countries):\n",
    "            country_data = raw_data[raw_data[country_col] == country].copy()\n",
    "            country_data = country_data.sort_values(year_col)\n",
    "            \n",
    "            if len(country_data) > 0 and prevalence_cols[0] in country_data.columns:\n",
    "                plt.plot(country_data[year_col], country_data[prevalence_cols[0]], \n",
    "                        'o-', label=country, color=colors[i], linewidth=2, markersize=6)\n",
    "        \n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel(prevalence_cols[0].replace('_', ' ').title())\n",
    "        plt.title(f'{prevalence_cols[0].replace(\"_\", \" \").title()} Trends for Sample Countries')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show detailed data for one country\n",
    "        sample_country = sample_countries[0]\n",
    "        sample_data = raw_data[raw_data[country_col] == sample_country].copy()\n",
    "        sample_data = sample_data.sort_values(year_col)\n",
    "        \n",
    "        print(f\"\\n=== DETAILED DATA FOR {sample_country.upper()} ===\")\n",
    "        display(sample_data[[year_col] + prevalence_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc9248",
   "metadata": {},
   "source": [
    "## 9. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    print(\"=== DATA QUALITY SUMMARY ===\")\n",
    "    \n",
    "    total_records = len(raw_data)\n",
    "    total_countries = raw_data[country_col].nunique() if country_col else 'Unknown'\n",
    "    total_years = raw_data[year_col].nunique() if year_col else 'Unknown'\n",
    "    total_metrics = len(prevalence_cols)\n",
    "    \n",
    "    print(f\"üìä Dataset Overview:\")\n",
    "    print(f\"   ‚Ä¢ Total records: {total_records:,}\")\n",
    "    print(f\"   ‚Ä¢ Countries/Entities: {total_countries}\")\n",
    "    print(f\"   ‚Ä¢ Years covered: {total_years}\")\n",
    "    print(f\"   ‚Ä¢ Mental health metrics: {total_metrics}\")\n",
    "    \n",
    "    # Data completeness\n",
    "    if prevalence_cols:\n",
    "        completeness = (raw_data[prevalence_cols].notna().sum() / len(raw_data)) * 100\n",
    "        avg_completeness = completeness.mean()\n",
    "        \n",
    "        print(f\"\\nüìà Data Completeness:\")\n",
    "        print(f\"   ‚Ä¢ Average completeness: {avg_completeness:.1f}%\")\n",
    "        \n",
    "        for metric, comp in completeness.items():\n",
    "            status = \"‚úì\" if comp >= 80 else \"‚ö†Ô∏è\" if comp >= 50 else \"‚ùå\"\n",
    "            print(f\"   ‚Ä¢ {metric}: {comp:.1f}% {status}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nüîç Next Steps:\")\n",
    "    print(f\"   1. Data cleaning and preprocessing needed\")\n",
    "    print(f\"   2. Handle missing values and outliers\")\n",
    "    print(f\"   3. Standardize country names and validate data\")\n",
    "    print(f\"   4. Create derived features and regional groupings\")\n",
    "    print(f\"   5. Proceed to detailed analysis\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data exploration completed successfully!\")\n",
    "    print(f\"üìÅ Proceed to notebook 02_data_cleaning.ipynb for data preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13197b43",
   "metadata": {},
   "source": [
    "## 10. Save Exploration Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_data is not None:\n",
    "    # Save basic exploration results\n",
    "    exploration_results = {\n",
    "        'dataset_shape': raw_data.shape,\n",
    "        'total_countries': raw_data[country_col].nunique() if country_col else 0,\n",
    "        'total_years': raw_data[year_col].nunique() if year_col else 0,\n",
    "        'year_range': [raw_data[year_col].min(), raw_data[year_col].max()] if year_col else [],\n",
    "        'prevalence_metrics': prevalence_cols,\n",
    "        'missing_data_summary': raw_data.isnull().sum().to_dict(),\n",
    "        'top_countries': raw_data[country_col].value_counts().head(10).to_dict() if country_col else {}\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    import json\n",
    "    results_path = Path(\"../data/processed/exploration_results.json\")\n",
    "    results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Convert numpy types for JSON serialization\n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return obj\n",
    "    \n",
    "    clean_results = {}\n",
    "    for key, value in exploration_results.items():\n",
    "        if isinstance(value, dict):\n",
    "            clean_results[key] = {k: convert_numpy(v) for k, v in value.items()}\n",
    "        else:\n",
    "            clean_results[key] = convert_numpy(value)\n",
    "    \n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(clean_results, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Exploration results saved to: {results_path}\")\n",
    "    print(f\"üìù Summary: {len(clean_results)} key findings documented\")\n",
    "else:\n",
    "    print(\"‚ùå No data available to save results\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
